{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import socket\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import (confusion_matrix,\n",
    "                             precision_recall_fscore_support, precision_score,\n",
    "                             recall_score, roc_curve)\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from model import Con2DAutoencoder\n",
    "from dataloaders.dataset_ZSL import VideoDataset, ImageDataset\n",
    "from network import Pac3D_ZSL_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device being used:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device being used: cuda\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "####    Parameters      ####\n",
    "############################\n",
    "nEpochs = 5  # Number of epochs for training\n",
    "resume_epoch = 0  # Default is 0, change if want to resume\n",
    "save_epoch = 10 # Store a model every save_epoch\n",
    "lr = 1e-3 # Learning rate\n",
    "clip_len = 256 # frames of each video\n",
    "domain = 'Auth' # DoS, DDoS, Auth, Web, Other    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain: Auth\n",
      "Attack List: ['BruteForce-FTP', 'BruteForce-SSH']\n",
      "Seen Class: ['BruteForce-SSH']\n",
      "Unseen Class: ['BruteForce-FTP']\n"
     ]
    }
   ],
   "source": [
    "embedding_path = '/SSD/p76111262/label_embedding_32'\n",
    "vector_map = []\n",
    "seen_vector_map = []\n",
    "unseen_vector_map = []\n",
    "\n",
    "if domain == 'DoS':\n",
    "    set_seed(6)\n",
    "    dataset = 'CIC-IDS2018-ZSL-DoS'\n",
    "    attack_list = ['DoS_Slowloris', 'DoS_SlowHTTPTest', 'DoS_Hulk', 'DoS_GoldenEye']\n",
    "    unseen_class = ['DoS_Slowloris']\n",
    "    seen_class = ['DoS_SlowHTTPTest', 'DoS_Hulk', 'DoS_GoldenEye']\n",
    "elif domain == 'DDoS':\n",
    "    set_seed(35)\n",
    "    dataset = 'CIC-IDS2018-ZSL-DDoS'\n",
    "    attack_list = ['DDoS_LOIC-UDP', 'DDoS_LOIC-HTTP', 'DDoS_HOIC'] \n",
    "    unseen_class = ['DDoS_LOIC-UDP']\n",
    "    seen_class = ['DDoS_LOIC-HTTP', 'DDoS_HOIC']\n",
    "elif domain == 'Auth':\n",
    "    set_seed(9)\n",
    "    dataset = 'CIC-IDS2018-ZSL-Auth'\n",
    "    attack_list = ['BruteForce-FTP', 'BruteForce-SSH']\n",
    "    unseen_class = ['BruteForce-FTP']\n",
    "    seen_class = ['BruteForce-SSH']\n",
    "elif domain == 'Web':\n",
    "    set_seed(2)\n",
    "    dataset = 'CIC-IDS2018-ZSL-Web'\n",
    "    attack_list = ['SQL-Injection', 'BruteForce-XSS', 'BruteForce-Web']\n",
    "    unseen_class = ['SQL-Injection']\n",
    "    seen_class = ['BruteForce-XSS', 'BruteForce-Web']\n",
    "elif domain == 'Other':\n",
    "    set_seed(21)\n",
    "    dataset = 'CIC-IDS2018-ZSL-Web'\n",
    "    attack_list = ['Infiltration', 'Botnet']\n",
    "    unseen_class = ['Infiltration']\n",
    "    seen_class = ['Botnet']\n",
    "\n",
    "saveName = 'Pac3D' + '-' + dataset\n",
    "\n",
    "print(\"Domain:\", domain)\n",
    "print(\"Attack List:\", attack_list)\n",
    "print(\"Seen Class:\", seen_class)\n",
    "print(\"Unseen Class:\", unseen_class)\n",
    "\n",
    "for a in attack_list:\n",
    "    file_name = os.path.join(embedding_path, f'{a}.npy')\n",
    "    vector_map.append(np.load(file_name))\n",
    "for seen in seen_class:\n",
    "    file_name = os.path.join(embedding_path, f'{seen}.npy')\n",
    "    seen_vector_map.append(np.load(file_name))\n",
    "for unseen in unseen_class:\n",
    "    file_name = os.path.join(embedding_path, f'{unseen}.npy')\n",
    "    unseen_vector_map.append(np.load(file_name))\n",
    "\n",
    "vector_map_tensors = [torch.tensor(vector, dtype=torch.float32) for vector in vector_map]\n",
    "seen_vector_map_tensors = [torch.tensor(vector, dtype=torch.float32) for vector in seen_vector_map]\n",
    "unseen_vector_map_tensors = [torch.tensor(vector, dtype=torch.float32) for vector in unseen_vector_map]\n",
    "vector_map_tensor = torch.stack(vector_map_tensors)\n",
    "seen_vector_map_tensor = torch.stack(seen_vector_map_tensors)\n",
    "unseen_vector_map_tensor = torch.stack(unseen_vector_map_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################\n",
    "####   Set Model result saving dir    ####\n",
    "##########################################\n",
    "save_dir_root = os.path.join(\"/SSD/p76111262/\")\n",
    "\n",
    "if resume_epoch != 0:\n",
    "    runs = sorted(glob.glob(os.path.join(save_dir_root, 'run', 'run_*')))\n",
    "    run_id = int(runs[-1].split('_')[-1]) if runs else 0\n",
    "else:\n",
    "    runs = sorted(glob.glob(os.path.join(save_dir_root, 'run', 'run_*')))\n",
    "    if len(runs) == 0:\n",
    "        run_id = 0\n",
    "    else:\n",
    "        run_id = max([int(i.split('_')[-1]) for i in runs]) + 1\n",
    "save_dir = os.path.join(save_dir_root, 'run', 'run_' + str(run_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 478\n",
      "Number of test images: 320\n",
      "Epoch [1/10], Loss: 0.0122\n",
      "Epoch [2/10], Loss: 0.0093\n",
      "Epoch [3/10], Loss: 0.0098\n",
      "Epoch [4/10], Loss: 0.0101\n",
      "Epoch [5/10], Loss: 0.0162\n",
      "Epoch [6/10], Loss: 0.0077\n",
      "Epoch [7/10], Loss: 0.0077\n",
      "Epoch [8/10], Loss: 0.0028\n",
      "Epoch [9/10], Loss: 0.0022\n",
      "Epoch [10/10], Loss: 0.0014\n",
      "Test Loss: 0.0015, Accuracy: 0.0000, Optimal Threshold: 1.0068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/p76111262/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:941: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
      "  warnings.warn(\"No negative samples in y_true, \"\n"
     ]
    }
   ],
   "source": [
    "# Function to find the optimal threshold from ROC curve\n",
    "def find_optimal_threshold(y_true, y_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "# Define the test function with accuracy calculation\n",
    "def AE_test(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    outputs = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            images = data.to(device)\n",
    "            reconstructed_images = model(images)\n",
    "            loss = criterion(reconstructed_images, images)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            reconstruction_error = torch.mean((reconstructed_images - images) ** 2, dim=[1, 2, 3]).cpu().numpy()\n",
    "            outputs.extend(reconstruction_error)\n",
    "            labels_list.extend(labels.cpu().numpy())\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    outputs = np.array(outputs)\n",
    "    labels_list = np.array(labels_list)\n",
    "    optimal_threshold = find_optimal_threshold(labels_list, outputs)\n",
    "    # 四捨五入到小數點第5位\n",
    "    optimal_threshold = round(optimal_threshold, 5)\n",
    "\n",
    "    predicted_labels = (outputs > optimal_threshold).astype(int)\n",
    "    accuracy = np.mean(predicted_labels == labels_list)\n",
    "    print(f'Test Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}, Optimal Threshold: {optimal_threshold:.4f}')\n",
    "    return optimal_threshold\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "AE_train_dataset = ImageDataset(root_dir='/SSD/p76111262/CIC-IDS2018-ZSL/DoS/train', transform=transform, unseen_class=unseen_class)\n",
    "AE_test_dataset = ImageDataset(root_dir='/SSD/p76111262/CIC-IDS2018-ZSL/DoS/test', transform=transform, unseen_class=unseen_class)\n",
    "print(f'Number of train images: {len(AE_train_dataset)}')\n",
    "print(f'Number of test images: {len(AE_test_dataset)}')\n",
    "AE_train_dataloader = DataLoader(AE_train_dataset, batch_size=10, shuffle=True)\n",
    "AE_test_dataloader = DataLoader(AE_test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Model\n",
    "AE_model = Con2DAutoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(AE_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for data, _ in AE_train_dataloader:\n",
    "        img = data.to(device)\n",
    "        # Forward pass\n",
    "        output = AE_model(img)\n",
    "        loss = criterion(output, img)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "optimal_threshold = test(AE_model, AE_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pac3D_ZSL_model.Pac3DClassifier(layer_sizes=(2, 2, 2, 2))\n",
    "train_params = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pac3D from scratch...\n",
      "Total params: 5.67M\n",
      "log dir: /SSD/p76111262/run/run_34/models/Jun11_22-25-49_uscc-ai-server\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "####   Load model & parameters    ####\n",
    "######################################\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "optimizer = optim.Adam(train_params, lr=lr, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # the scheduler divides the lr by 10 every 5 epochs\n",
    "\n",
    "if resume_epoch == 0:\n",
    "    print(\"Training {} from scratch...\".format('Pac3D'))\n",
    "else:\n",
    "    checkpoint = torch.load(os.path.join(save_dir, 'models', saveName + '_epoch-' + str(resume_epoch - 1) + '.pth.tar'),\n",
    "                    map_location=lambda storage, loc: storage)   # Load all tensors onto the CPU\n",
    "    print(\"Initializing weights from: {}...\".format(\n",
    "        os.path.join(save_dir, 'models', saveName + '_epoch-' + str(resume_epoch - 1) + '.pth.tar')))\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['opt_dict'])\n",
    "\n",
    "print('Total params: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "log_dir = os.path.join(save_dir, 'models', datetime.now().strftime('%b%d_%H-%M-%S') + '_' + socket.gethostname())\n",
    "print(\"log dir:\", log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model on CIC-IDS2018-ZSL-Auth dataset...\n",
      "train_labels_index: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "test_labels_index: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "########################\n",
    "####   Load Data    ####\n",
    "########################\n",
    "print('Training model on {} dataset...'.format(dataset))\n",
    "train_dataloader = DataLoader(VideoDataset(dataset=dataset, split='train', clip_len=clip_len, embedding_map=vector_map, attack_list=seen_class), batch_size=4, shuffle=True, num_workers=0)\n",
    "test_dataloader  = DataLoader(VideoDataset(dataset=dataset, split='test', clip_len=clip_len, embedding_map=vector_map, attack_list=attack_list), batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "train_size = len(train_dataloader.dataset)\n",
    "test_size = len(test_dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:30<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 1/10 Loss: 0.04560464322566986 Acc: 1.0\n",
      "Execution time: 30.775944333989173\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:25<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch: 2/10 Loss: 0.003132275119423866 Acc: 1.0\n",
      "Execution time: 25.17948939197231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [00:16<00:09,  1.53it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3718756/2323361634.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target = torch.ones(train_size, dtype=torch.float32, device=device)\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "for epoch in range(resume_epoch, nEpochs):\n",
    "    start_time = timeit.default_timer()\n",
    "    # reset the running loss and corrects\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    for inputs, embedding, label in tqdm(train_dataloader):\n",
    "        # move inputs and labels to the device the training is taking place on\n",
    "        inputs = Variable(inputs, requires_grad=True).to(device)\n",
    "        embedding = Variable(embedding).to(device)\n",
    "        label = Variable(label).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        batch_size = outputs.size(0)\n",
    "        target = torch.ones(batch_size, device=outputs.device)\n",
    "        loss = criterion(outputs, embedding, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        seen_vector_map_tensor = seen_vector_map_tensor.to(device)  \n",
    "        similarities = F.cosine_similarity(outputs.unsqueeze(1), seen_vector_map_tensor.unsqueeze(0), dim=2)\n",
    "        preds = torch.argmax(similarities, dim=1)\n",
    "        running_corrects += torch.sum(preds == label)\n",
    "        \n",
    "    epoch_loss = running_loss / train_size\n",
    "    epoch_acc = running_corrects.double() / train_size\n",
    "\n",
    "    writer.add_scalar('data/train_loss_epoch', epoch_loss, epoch)\n",
    "    writer.add_scalar('data/train_acc_epoch', epoch_acc, epoch)\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accs.append(epoch_acc)\n",
    "\n",
    "    print(\"[train] Epoch: {}/{} Loss: {} Acc: {}\".format(epoch+1, nEpochs, epoch_loss, epoch_acc))\n",
    "    stop_time = timeit.default_timer()\n",
    "    print(\"Execution time: \" + str(stop_time - start_time) + \"\\n\")\n",
    "\n",
    "    if epoch % save_epoch == (save_epoch - 1):\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'opt_dict': optimizer.state_dict(),\n",
    "        }, os.path.join(save_dir, 'models', saveName + '_epoch-' + str(epoch) + '.pth.tar'))\n",
    "        print(\"Save model at {}\\n\".format(os.path.join(save_dir, 'models', saveName + '_epoch-' + str(epoch) + '.pth.tar')))\n",
    "\n",
    "writer.close()\n",
    "torch.save(model.state_dict(), \"/SSD/p76111262/\"+'Pac3D_run'+str(run_id)+\".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dataloader, device, optimal_threshold):\n",
    "    model.eval()\n",
    "    # AE_model.eval()\n",
    "    running_corrects = 0\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for (inputs, embedding, label), (AE_input, AE_labels) in tqdm(zip(test_dataloader, AE_test_dataloader), total=len(test_dataloader)):\n",
    "        inputs = inputs.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        images = AE_input.to(device)\n",
    "        with torch.no_grad():\n",
    "            reconstructed_images = AE_model(images)\n",
    "        reconstruction_error = torch.mean((reconstructed_images - images) ** 2, dim=[1, 2, 3]).cpu().numpy()\n",
    "        \n",
    "        is_seen = reconstruction_error < optimal_threshold\n",
    "        for i in range(inputs.size(0)):\n",
    "            if is_seen[i]:\n",
    "                vector_map_tensor = seen_vector_map_tensor.to(device)\n",
    "            else:\n",
    "                vector_map_tensor = unseen_vector_map_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs[i].unsqueeze(0))\n",
    "\n",
    "        # 計算每個輸出與所有標籤向量之間的 cosine similarity\n",
    "        similarities = F.cosine_similarity(outputs.unsqueeze(1), vector_map_tensor.unsqueeze(0), dim=2)\n",
    "        print(\"similarities:\", similarities)\n",
    "        pred = similarities.argmax().item()  # 預測為最相似向量的索\n",
    "        correct = (pred == label).sum().item()\n",
    "        running_corrects += correct\n",
    "\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(label[i].item())\n",
    "\n",
    "    epoch_acc = running_corrects / len(test_dataloader.dataset)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(\"[Test] Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}\".format(epoch_acc, precision, recall))\n",
    "    return y_true, y_pred\n",
    "\n",
    "# 调用测试函数\n",
    "y_true, y_pred = test(model, test_dataloader, device, optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_pred:\", y_pred)\n",
    "print(\"y_true:\", y_true)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = list(range(nEpochs))\n",
    "plt.plot(x, train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.savefig(save_dir + '/training_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 製作混淆矩陣\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)                               \n",
    "# 計算每個class的accuracy\n",
    "per_cls_acc = cf_matrix.diagonal()/cf_matrix.sum(axis=0)                   \n",
    "\n",
    "class_names = []\n",
    "label_txt = os.path.join('dataloaders', dataset + \".txt\")  # 這裡要改成你的label.txt路徑\n",
    "with open(label_txt, 'r') as f:\n",
    "    for line in f:\n",
    "        class_names.append(line.strip())\n",
    "        \n",
    "print(class_names)\n",
    "print(per_cls_acc)                                            \n",
    "\n",
    "# 開始繪製混淆矩陣並存檔\n",
    "df_cm = pd.DataFrame(cf_matrix, class_names, class_names)    \n",
    "plt.figure(figsize = (9,6))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='BuGn')\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"label (ground truth)\")\n",
    "plt.savefig(save_dir + '/confusion_matrix.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
