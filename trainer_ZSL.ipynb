{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import socket\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics import (auc, confusion_matrix,\n",
    "                             precision_recall_fscore_support, precision_score,\n",
    "                             recall_score, roc_curve)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from model import Con2DAutoencoder\n",
    "from dataloaders.dataset_ZSL import VideoDataset, ImageDataset\n",
    "from network import Pac3D_ZSL_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "####    Parameters      ####\n",
    "############################\n",
    "nEpochs = 10  # Number of epochs for training\n",
    "resume_epoch = 0  # Default is 0, change if want to resume\n",
    "useTest = True # See evolution of the test set when training\n",
    "nTestInterval = 10 # Run on test set every nTestInterval epochs\n",
    "save_epoch = 10 # Store a model every save_epoch\n",
    "lr = 1e-3 # Learning rate\n",
    "clip_len = 256 # frames of each video\n",
    "\n",
    "###################################\n",
    "####    Options of Dataset     ####\n",
    "###################################\n",
    "dataset = 'CIC-IDS2018-ZSL-DoS' \n",
    "domain = 'DoS' # DoS, DDoS, Auth, Web, Other    \n",
    "saveName = 'Pac3D' + '-' + dataset\n",
    "\n",
    "if dataset == 'CIC-IDS2018':\n",
    "    set_seed(7)\n",
    "elif dataset == 'CIC-IDS2018-ZSL-DDoS':\n",
    "    set_seed(35)\n",
    "elif dataset == 'CIC-IDS2018-ZSL-DoS':\n",
    "    set_seed(6)\n",
    "elif dataset == 'CIC-IDS2018-ZSL-Auth':\n",
    "    set_seed(9)\n",
    "elif dataset == 'CIC-IDS2018-ZSL-Web':\n",
    "    set_seed(2)\n",
    "elif dataset == 'CIC-IDS2018-ZSL-Other':\n",
    "    set_seed(21)\n",
    "else:\n",
    "    print('No Dataset')\n",
    "    raise NotImplementedError\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device being used:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_path = '/SSD/p76111262/label_embedding_32'\n",
    "vector_map = []\n",
    "seen_vector_map = []\n",
    "unseen_vector_map = []\n",
    "\n",
    "if domain == 'DoS':\n",
    "    attack_list = ['DoS_SlowHTTPTest', 'DoS_Slowloris', 'DoS_Hulk', 'DoS_GoldenEye']\n",
    "    unseen_class = ['DoS_Slowloris']\n",
    "    seen_class = ['DoS_SlowHTTPTest', 'DoS_Hulk', 'DoS_GoldenEye']\n",
    "elif domain == 'DDoS':\n",
    "    attack_list = ['DDoS_LOIC-HTTP', 'DDoS_HOIC', 'DDoS_LOIC-UDP'] \n",
    "    unseen_class = ['DDoS_LOIC-UDP']\n",
    "    seen_class = ['DDoS_LOIC-HTTP', 'DDoS_HOIC']\n",
    "elif domain == 'Auth':\n",
    "    attack_list = ['BruteForce-SSH', 'BruteForce-FTP']\n",
    "    unseen_class = ['BruteForce-FTP']\n",
    "    seen_class = ['BruteForce-SSH']\n",
    "elif domain == 'Web':\n",
    "    attack_list = ['BruteForce-XSS', 'BruteForce-Web', 'SQL-Injection']\n",
    "    unseen_class = ['SQL-Injection']\n",
    "    seen_class = ['BruteForce-XSS', 'BruteForce-Web']\n",
    "elif domain == 'Other':\n",
    "    attack_list = ['Infiltration', 'Botnet']\n",
    "    unseen_class = ['Infiltration']\n",
    "    seen_class = ['Botnet']\n",
    "\n",
    "print(\"Domain:\", domain)\n",
    "print(\"Attack List:\", attack_list)\n",
    "print(\"Seen Class:\", seen_class)\n",
    "print(\"Unseen Class:\", unseen_class)\n",
    "\n",
    "for a in attack_list:\n",
    "    file_name = os.path.join(embedding_path, f'{a}.npy')\n",
    "    vector_map.append(np.load(file_name))\n",
    "for seen in seen_class:\n",
    "    file_name = os.path.join(embedding_path, f'{seen}.npy')\n",
    "    seen_vector_map.append(np.load(file_name))\n",
    "for unseen in unseen_class:\n",
    "    file_name = os.path.join(embedding_path, f'{unseen}.npy')\n",
    "    unseen_vector_map.append(np.load(file_name))\n",
    "\n",
    "vector_map_tensors = [torch.tensor(vector, dtype=torch.float32) for vector in vector_map]\n",
    "seen_vector_map_tensors = [torch.tensor(vector, dtype=torch.float32) for vector in seen_vector_map]\n",
    "unseen_vector_map_tensors = [torch.tensor(vector, dtype=torch.float32) for vector in unseen_vector_map]\n",
    "vector_map_tensor = torch.stack(vector_map_tensors)\n",
    "seen_vector_map_tensor = torch.stack(seen_vector_map_tensors)\n",
    "unseen_vector_map_tensor = torch.stack(unseen_vector_map_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##########################################\n",
    "####   Set Model result saving dir    ####\n",
    "##########################################\n",
    "save_dir_root = os.path.join(\"/SSD/p76111262/\")\n",
    "resume_epoch = 0\n",
    "\n",
    "if resume_epoch != 0:\n",
    "    runs = sorted(glob.glob(os.path.join(save_dir_root, 'run', 'run_*')))\n",
    "    run_id = int(runs[-1].split('_')[-1]) if runs else 0\n",
    "else:\n",
    "    runs = sorted(glob.glob(os.path.join(save_dir_root, 'run', 'run_*')))\n",
    "    if len(runs) == 0:\n",
    "        run_id = 0\n",
    "    else:\n",
    "        run_id = max([int(i.split('_')[-1]) for i in runs]) + 1\n",
    "save_dir = os.path.join(save_dir_root, 'run', 'run_' + str(run_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the optimal threshold from ROC curve\n",
    "def find_optimal_threshold(y_true, y_scores):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "# Define the test function with accuracy calculation\n",
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    outputs = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            images = data.to(device)\n",
    "            reconstructed_images = model(images)\n",
    "            loss = criterion(reconstructed_images, images)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            reconstruction_error = torch.mean((reconstructed_images - images) ** 2, dim=[1, 2, 3]).cpu().numpy()\n",
    "            outputs.extend(reconstruction_error)\n",
    "            labels_list.extend(labels.cpu().numpy())\n",
    "\n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    outputs = np.array(outputs)\n",
    "    labels_list = np.array(labels_list)\n",
    "    optimal_threshold = find_optimal_threshold(labels_list, outputs)\n",
    "    # 四捨五入到小數點第5位\n",
    "    optimal_threshold = round(optimal_threshold, 5)\n",
    "\n",
    "    predicted_labels = (outputs > optimal_threshold).astype(int)\n",
    "    accuracy = np.mean(predicted_labels == labels_list)\n",
    "    print(f'Test Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}, Optimal Threshold: {optimal_threshold:.4f}')\n",
    "    return optimal_threshold\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "AE_train_dataset = ImageDataset(root_dir='/SSD/p76111262/CIC-IDS2018-ZSL/DoS/train', transform=transform, unseen_class=unseen_class)\n",
    "AE_test_dataset = ImageDataset(root_dir='/SSD/p76111262/CIC-IDS2018-ZSL/DoS/test', transform=transform, unseen_class=unseen_class)\n",
    "print(f'Number of train images: {len(AE_train_dataset)}')\n",
    "print(f'Number of test images: {len(AE_test_dataset)}')\n",
    "AE_train_dataloader = DataLoader(AE_train_dataset, batch_size=10, shuffle=True)\n",
    "AE_test_dataloader = DataLoader(AE_test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Model\n",
    "AE_model = Con2DAutoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(AE_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for data, _ in AE_train_dataloader:\n",
    "        img = data.to(device)\n",
    "        # Forward pass\n",
    "        output = AE_model(img)\n",
    "        loss = criterion(output, img)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "optimal_threshold = test(AE_model, AE_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pac3D_ZSL_model.Pac3DClassifier(layer_sizes=(2, 2, 2, 2))\n",
    "train_params = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "####   Load model & parameters    ####\n",
    "######################################\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "optimizer = optim.Adam(train_params, lr=lr, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)  # the scheduler divides the lr by 10 every 5 epochs\n",
    "\n",
    "if resume_epoch == 0:\n",
    "    print(\"Training {} from scratch...\".format('Pac3D'))\n",
    "else:\n",
    "    checkpoint = torch.load(os.path.join(save_dir, 'models', saveName + '_epoch-' + str(resume_epoch - 1) + '.pth.tar'),\n",
    "                    map_location=lambda storage, loc: storage)   # Load all tensors onto the CPU\n",
    "    print(\"Initializing weights from: {}...\".format(\n",
    "        os.path.join(save_dir, 'models', saveName + '_epoch-' + str(resume_epoch - 1) + '.pth.tar')))\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['opt_dict'])\n",
    "\n",
    "print('Total params: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "log_dir = os.path.join(save_dir, 'models', datetime.now().strftime('%b%d_%H-%M-%S') + '_' + socket.gethostname())\n",
    "print(\"log dir:\", log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################\n",
    "####   Load Data    ####\n",
    "########################\n",
    "print('Training model on {} dataset...'.format(dataset))\n",
    "train_dataloader = DataLoader(VideoDataset(dataset=dataset, split='train', clip_len=clip_len, embedding_map=vector_map, attack_list=seen_class), batch_size=4, shuffle=True, num_workers=0)\n",
    "test_dataloader  = DataLoader(VideoDataset(dataset=dataset, split='test', clip_len=clip_len, embedding_map=vector_map, attack_list=attack_list), batch_size=4, shuffle=False, num_workers=0)\n",
    "\n",
    "train_size = len(train_dataloader.dataset)\n",
    "test_size = len(test_dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.ones(train_size, dtype=torch.float32, device=device)\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for epoch in range(resume_epoch, nEpochs):\n",
    "    start_time = timeit.default_timer()\n",
    "    # reset the running loss and corrects\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "\n",
    "    # set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    for inputs, embedding, label in tqdm(train_dataloader):\n",
    "        # move inputs and labels to the device the training is taking place on\n",
    "        inputs = Variable(inputs, requires_grad=True).to(device)\n",
    "        embedding = Variable(embedding).to(device)\n",
    "        label = Variable(label).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        batch_size = outputs.size(0)\n",
    "        target = torch.ones(batch_size, device=outputs.device)\n",
    "        loss = criterion(outputs, embedding, target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        seen_vector_map_tensor = seen_vector_map_tensor.to(device)  \n",
    "        similarities = F.cosine_similarity(outputs.unsqueeze(1), seen_vector_map_tensor.unsqueeze(0), dim=2)\n",
    "        preds = torch.argmax(similarities, dim=1)\n",
    "        running_corrects += torch.sum(preds == label)\n",
    "        \n",
    "    epoch_loss = running_loss / train_size\n",
    "    epoch_acc = running_corrects.double() / train_size\n",
    "\n",
    "    writer.add_scalar('data/train_loss_epoch', epoch_loss, epoch)\n",
    "    writer.add_scalar('data/train_acc_epoch', epoch_acc, epoch)\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accs.append(epoch_acc)\n",
    "\n",
    "    print(\"[train] Epoch: {}/{} Loss: {} Acc: {}\".format(epoch+1, nEpochs, epoch_loss, epoch_acc))\n",
    "    stop_time = timeit.default_timer()\n",
    "    print(\"Execution time: \" + str(stop_time - start_time) + \"\\n\")\n",
    "\n",
    "    if epoch % save_epoch == (save_epoch - 1):\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'opt_dict': optimizer.state_dict(),\n",
    "        }, os.path.join(save_dir, 'models', saveName + '_epoch-' + str(epoch) + '.pth.tar'))\n",
    "        print(\"Save model at {}\\n\".format(os.path.join(save_dir, 'models', saveName + '_epoch-' + str(epoch) + '.pth.tar')))\n",
    "\n",
    "writer.close()\n",
    "torch.save(model.state_dict(), \"/SSD/p76111262/\"+'Pac3D_run'+str(run_id)+\".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_with_cosine_similarity(model, test_dataloader, device, optimal_threshold):\n",
    "    model.eval()\n",
    "    # AE_model.eval()\n",
    "    running_corrects = 0\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    for (inputs, embedding, label), (AE_input, AE_labels) in tqdm(zip(test_dataloader, AE_test_dataloader), total=len(test_dataloader)):\n",
    "        inputs = inputs.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        images = AE_input.to(device)\n",
    "        with torch.no_grad():\n",
    "            reconstructed_images = AE_model(images)\n",
    "        reconstruction_error = torch.mean((reconstructed_images - images) ** 2, dim=[1, 2, 3]).cpu().numpy()\n",
    "        \n",
    "        is_seen = reconstruction_error < optimal_threshold\n",
    "        for i in range(inputs.size(0)):\n",
    "            if is_seen[i]:\n",
    "                vector_map_tensor = seen_vector_map_tensor.to(device)\n",
    "            else:\n",
    "                vector_map_tensor = unseen_vector_map_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs[i].unsqueeze(0))\n",
    "\n",
    "        # 計算每個輸出與所有標籤向量之間的 cosine similarity\n",
    "        similarities = F.cosine_similarity(outputs, vector_map_tensor.unsqueeze(0), dim=1)\n",
    "        pred = similarities.argmax().item()  # 預測為最相似向量的索引\n",
    "        correct = (pred == label).sum().item()\n",
    "        running_corrects += correct\n",
    "\n",
    "        y_pred.append(pred)\n",
    "        y_true.append(label[i].item())\n",
    "\n",
    "    epoch_acc = running_corrects / len(test_dataloader.dataset)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    print(\"[Test] Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}\".format(epoch_acc, precision, recall))\n",
    "    return y_true, y_pred\n",
    "\n",
    "# 调用测试函数\n",
    "y_true, y_pred = test_model_with_cosine_similarity(model, test_dataloader, device, optimal_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_pred:\", y_pred)\n",
    "print(\"y_true:\", y_true)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = list(range(nEpochs))\n",
    "plt.plot(x, train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.savefig(save_dir + '/training_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 製作混淆矩陣\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)                               \n",
    "# 計算每個class的accuracy\n",
    "per_cls_acc = cf_matrix.diagonal()/cf_matrix.sum(axis=0)                   \n",
    "\n",
    "class_names = []\n",
    "label_txt = os.path.join('dataloaders', dataset + \".txt\")  # 這裡要改成你的label.txt路徑\n",
    "with open(label_txt, 'r') as f:\n",
    "    for line in f:\n",
    "        class_names.append(line.strip())\n",
    "        \n",
    "print(class_names)\n",
    "print(per_cls_acc)                                            \n",
    "\n",
    "# 開始繪製混淆矩陣並存檔\n",
    "df_cm = pd.DataFrame(cf_matrix, class_names, class_names)    \n",
    "plt.figure(figsize = (9,6))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='BuGn')\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"label (ground truth)\")\n",
    "plt.savefig(save_dir + '/confusion_matrix.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
