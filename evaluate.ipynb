{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from dataloaders.dataset import VideoDataset\n",
    "from network import R3D_model, C3D_model, R2Plus1D_model, HM3D_model, Pac3D_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################################\n",
    "####   Load model & parameters    ####\n",
    "######################################\n",
    "criterion = nn.CrossEntropyLoss()  # standard crossentropy loss for classification\n",
    "optimizer = optim.Adam(train_params, lr=lr, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10,\n",
    "                                        gamma=0.1)  # the scheduler divides the lr by 10 every 10 epochs\n",
    "\n",
    "if resume_epoch == 0:\n",
    "    print(\"Training {} from scratch...\".format(modelName))\n",
    "else:\n",
    "    checkpoint = torch.load(os.path.join(save_dir, 'models', saveName + '_epoch-' + str(resume_epoch - 1) + '.pth.tar'),\n",
    "                    map_location=lambda storage, loc: storage)   # Load all tensors onto the CPU\n",
    "    print(\"Initializing weights from: {}...\".format(\n",
    "        os.path.join(save_dir, 'models', saveName + '_epoch-' + str(resume_epoch - 1) + '.pth.tar')))\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['opt_dict'])\n",
    "\n",
    "print('Total params: %.2fM' % (sum(p.numel() for p in model.parameters()) / 1000000.0))\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "log_dir = os.path.join(save_dir, 'models', datetime.now().strftime('%b%d_%H-%M-%S') + '_' + socket.gethostname())\n",
    "print(log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(save_dir, 'models', saveName + '_epoch-' + str(nEpochs - 1) + '.pth.tar'),\n",
    "                    map_location=lambda storage, loc: storage)   # Load all tensors onto the CPU\n",
    "print(\"Initializing weights from: {}...\".format(os.path.join(save_dir, 'models', saveName + '_epoch-' + str(nEpochs - 1) + '.pth.tar')))\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['opt_dict'])\n",
    "y_pred, y_true = check_accuracy(test_dataloader, model)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
